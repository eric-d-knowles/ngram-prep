{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Setup**\n",
    "## Recompile Cython Extensions"
   ],
   "id": "b784e1a1cda09447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:18:10.124964Z",
     "start_time": "2025-10-06T18:18:00.885407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /scratch/edk202/ngram-prep\n",
    "\n",
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "\n",
    "%pip install -e . --no-build-isolation -q"
   ],
   "id": "1ad267332e4b1fcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/edk202/ngram-prep\n",
      "env: LC_ALL=C.UTF-8\n",
      "env: LANG=C.UTF-8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "a8e3ef360e1fe339"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:18:10.990474Z",
     "start_time": "2025-10-06T18:18:10.128846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auto-reload edited scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# NLTK resources\n",
    "from nltk.corpus import stopwords; stopwords = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import WordNetLemmatizer; lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Ngram acquisition functions\n",
    "from ngram_acquire.pipeline.orchestrate import download_and_ingest_to_rocksdb\n",
    "from ngram_acquire.pipeline.logger import setup_logger\n",
    "\n",
    "# Ngram processing functions\n",
    "from pathlib import Path\n",
    "from ngram_filter.config import PipelineConfig, FilterConfig\n",
    "from ngram_filter.pipeline.orchestrator import build_processed_db"
   ],
   "id": "1998c9fafc32aa8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up logging to file",
   "id": "abd0247891250279"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:18:13.711963Z",
     "start_time": "2025-10-06T18:18:13.532547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "setup_logger(\n",
    "    db_path=\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams.db\",\n",
    "    console=False,\n",
    "    rotate=True,\n",
    "    max_bytes=100_000_000,\n",
    "    backup_count=5,\n",
    "    force=True\n",
    ")"
   ],
   "id": "34a1e1724ae74cc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams.db/ngram_download_20251006_141813.log')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Download Unigrams and Ingest to RocksDB**",
   "id": "879927f391b65d8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:26:47.875066Z",
     "start_time": "2025-10-06T18:18:13.715727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_and_ingest_to_rocksdb(\n",
    "    ngram_size=1,\n",
    "    repo_release_id=\"20200217\",\n",
    "    repo_corpus_id=\"eng\",\n",
    "    db_path_stub=\"/vast/edk202/NLP_corpora/Google_Books/\",\n",
    "    file_range=(0, 23),\n",
    "    random_seed=21,\n",
    "    workers=30,\n",
    "    use_threads=False,\n",
    "    ngram_type=\"tagged\",\n",
    "    overwrite_db=True,\n",
    "    overwrite_checkpoint=True,\n",
    "    write_batch_size=100_000,\n",
    "    open_type=\"write:packed24\",\n",
    "    post_compact=False,\n",
    ")"
   ],
   "id": "23449b75707ae1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM ACQUISITION PIPELINE\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "Start Time: 2025-10-06 14:18:13\n",
      "\n",
      "Download Configuration\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "Ngram repo:           https://books.storage.googleapis.com/?prefix=ngrams/books/20200217/eng/1-\n",
      "DB path:              /vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams.db\n",
      "File range:           0 to 23\n",
      "Total files:          24\n",
      "Files to get:         24\n",
      "Skipping:             0\n",
      "Download workers:     30\n",
      "Batch size:           100,000\n",
      "Ngram size:           1\n",
      "Ngram type:           tagged\n",
      "Overwrite DB:         True\n",
      "Overwrite checkpoint: False\n",
      "DB Profile:           write:packed24\n",
      "Compact:              False\n",
      "\n",
      "Download Progress\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Processed: 100%|█████████████████████████████████████████████████████████| 24/24 [08:00<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete!\n",
      "\n",
      "Final Summary\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "Fully processed files:       24\n",
      "Failed files:                0\n",
      "Total entries written:       41,783,218\n",
      "Write batches flushed:       24\n",
      "Uncompressed data processed: 43.28 GB\n",
      "Processing throughput:       86.20 MB/sec\n",
      "\n",
      "End Time: 2025-10-06 14:26:47.869106\n",
      "Total Runtime: 0:08:34.107396\n",
      "Time per file: 0:00:21.421142\n",
      "Files per hour: 168.1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Run Processing Pipeline**",
   "id": "97d09d26c6f2043f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:39:10.234504Z",
     "start_time": "2025-10-06T18:26:47.974167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_db = Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams.db\")\n",
    "dst_db = src_db.parent / \"1grams_processed.db\"\n",
    "tmp_dir = src_db.parent / \"processing_tmp\"\n",
    "\n",
    "pipeline_config = PipelineConfig(\n",
    "    src_db=src_db,\n",
    "    dst_db=dst_db,\n",
    "    tmp_dir=tmp_dir,\n",
    "    readers=32,\n",
    "    ingestors=32,\n",
    "    work_units_per_reader=1,\n",
    "    partitioning_sample_rate=0.01,\n",
    "    prefix_length=4,\n",
    "    mode=\"restart\",\n",
    "    force_cache_use=False,\n",
    "    enable_ingest=True,\n",
    "    delete_after_ingest=True,\n",
    "    post_compact=True,\n",
    "    overwrite_checkpoint=True,\n",
    "    progress_every_s=60.0,\n",
    "    output_whitelist_path=dst_db / \"whitelist.txt\",\n",
    "    output_whitelist_top_n=40_000\n",
    ")\n",
    "\n",
    "filter_config = FilterConfig(\n",
    "    stop_set=stopwords,\n",
    "    lemma_gen=lemmatizer,\n",
    ")\n",
    "\n",
    "build_processed_db(pipeline_config, filter_config)"
   ],
   "id": "57db436f73cba01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM FILTER PIPELINE\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      "Configuration:\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "\u001B[4mPipeline\u001B[0m\n",
      "Run mode: restart\n",
      "Ingest after filtering: True\n",
      "Compact after ingesting: True\n",
      "  \n",
      "\u001B[4mWorkers\u001B[0m\n",
      "Num Workers: 32\n",
      "Work units: 32\n",
      "Profiles: read=read:packed24, write=write:packed24\n",
      "Buffer: 100,000 items, 128MB\n",
      "  \n",
      "\u001B[4mFiles\u001B[0m\n",
      "Source: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams.db\n",
      "Destination: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams_processed.db\n",
      "Input whitelist: None\n",
      "Output whitelist: ...ks/20200217/eng/1gram_files/1grams_processed.db/whitelist.txt (top 40,000 keys)\n",
      "\n",
      "Phase 1: Creating work units...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "Clean restart - resampling and creating new work units\n",
      "Sampling database at 0.01000 rate (prefix_length=4)...\n",
      "Targeting 417,832 samples using reservoir sampling\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "RESERVOIR SAMPLING CONFIGURATION\n",
      "────────────────────────────────────────────────────────────\n",
      "Target sample size:     417,832 items\n",
      "Database size:          41,783,242 items\n",
      "Progress reporting:     Every 1% complete\n",
      "Database limit:         No limit (full traversal)\n",
      "────────────────────────────────────────────────────────────\n",
      "Progress: 1.0% (417,833 items)\n",
      "Progress: 2.0% (835,665 items)\n",
      "Progress: 3.0% (1,253,498 items)\n",
      "Progress: 4.0% (1,671,330 items)\n",
      "Progress: 5.0% (2,089,163 items)\n",
      "Progress: 6.0% (2,506,995 items)\n",
      "Progress: 7.0% (2,924,827 items)\n",
      "Progress: 8.0% (3,342,660 items)\n",
      "Progress: 9.0% (3,760,492 items)\n",
      "Progress: 10.0% (4,178,325 items)\n",
      "Progress: 11.0% (4,596,157 items)\n",
      "Progress: 12.0% (5,013,990 items)\n",
      "Progress: 13.0% (5,431,822 items)\n",
      "Progress: 14.0% (5,849,654 items)\n",
      "Progress: 15.0% (6,267,487 items)\n",
      "Progress: 16.0% (6,685,319 items)\n",
      "Progress: 17.0% (7,103,152 items)\n",
      "Progress: 18.0% (7,520,984 items)\n",
      "Progress: 19.0% (7,938,816 items)\n",
      "Progress: 20.0% (8,356,649 items)\n",
      "Progress: 21.0% (8,774,481 items)\n",
      "Progress: 22.0% (9,192,314 items)\n",
      "Progress: 23.0% (9,610,146 items)\n",
      "Progress: 24.0% (10,027,979 items)\n",
      "Progress: 25.0% (10,445,811 items)\n",
      "Progress: 26.0% (10,863,643 items)\n",
      "Progress: 27.0% (11,281,476 items)\n",
      "Progress: 28.0% (11,699,308 items)\n",
      "Progress: 29.0% (12,117,141 items)\n",
      "Progress: 30.0% (12,534,973 items)\n",
      "Progress: 31.0% (12,952,806 items)\n",
      "Progress: 32.0% (13,370,638 items)\n",
      "Progress: 33.0% (13,788,470 items)\n",
      "Progress: 34.0% (14,206,303 items)\n",
      "Progress: 35.0% (14,624,135 items)\n",
      "Progress: 36.0% (15,041,968 items)\n",
      "Progress: 37.0% (15,459,800 items)\n",
      "Progress: 38.0% (15,877,632 items)\n",
      "Progress: 39.0% (16,295,465 items)\n",
      "Progress: 40.0% (16,713,297 items)\n",
      "Progress: 41.0% (17,131,130 items)\n",
      "Progress: 42.0% (17,548,962 items)\n",
      "Progress: 43.0% (17,966,795 items)\n",
      "Progress: 44.0% (18,384,627 items)\n",
      "Progress: 45.0% (18,802,459 items)\n",
      "Progress: 46.0% (19,220,292 items)\n",
      "Progress: 47.0% (19,638,124 items)\n",
      "Progress: 48.0% (20,055,957 items)\n",
      "Progress: 49.0% (20,473,789 items)\n",
      "Progress: 50.0% (20,891,621 items)\n",
      "Progress: 51.0% (21,309,454 items)\n",
      "Progress: 52.0% (21,727,286 items)\n",
      "Progress: 53.0% (22,145,119 items)\n",
      "Progress: 54.0% (22,562,951 items)\n",
      "Progress: 55.0% (22,980,784 items)\n",
      "Progress: 56.0% (23,398,616 items)\n",
      "Progress: 57.0% (23,816,448 items)\n",
      "Progress: 58.0% (24,234,281 items)\n",
      "Progress: 59.0% (24,652,113 items)\n",
      "Progress: 60.0% (25,069,946 items)\n",
      "Progress: 61.0% (25,487,778 items)\n",
      "Progress: 62.0% (25,905,611 items)\n",
      "Progress: 63.0% (26,323,443 items)\n",
      "Progress: 64.0% (26,741,275 items)\n",
      "Progress: 65.0% (27,159,108 items)\n",
      "Progress: 66.0% (27,576,940 items)\n",
      "Progress: 67.0% (27,994,773 items)\n",
      "Progress: 68.0% (28,412,605 items)\n",
      "Progress: 69.0% (28,830,437 items)\n",
      "Progress: 70.0% (29,248,270 items)\n",
      "Progress: 71.0% (29,666,102 items)\n",
      "Progress: 72.0% (30,083,935 items)\n",
      "Progress: 73.0% (30,501,767 items)\n",
      "Progress: 74.0% (30,919,600 items)\n",
      "Progress: 75.0% (31,337,432 items)\n",
      "Progress: 76.0% (31,755,264 items)\n",
      "Progress: 77.0% (32,173,097 items)\n",
      "Progress: 78.0% (32,590,929 items)\n",
      "Progress: 79.0% (33,008,762 items)\n",
      "Progress: 80.0% (33,426,594 items)\n",
      "Progress: 81.0% (33,844,427 items)\n",
      "Progress: 82.0% (34,262,259 items)\n",
      "Progress: 83.0% (34,680,091 items)\n",
      "Progress: 84.0% (35,097,924 items)\n",
      "Progress: 85.0% (35,515,756 items)\n",
      "Progress: 86.0% (35,933,589 items)\n",
      "Progress: 87.0% (36,351,421 items)\n",
      "Progress: 88.0% (36,769,253 items)\n",
      "Progress: 89.0% (37,187,086 items)\n",
      "Progress: 90.0% (37,604,918 items)\n",
      "Progress: 91.0% (38,022,751 items)\n",
      "Progress: 92.0% (38,440,583 items)\n",
      "Progress: 93.0% (38,858,416 items)\n",
      "Progress: 94.0% (39,276,248 items)\n",
      "Progress: 95.0% (39,694,080 items)\n",
      "Progress: 96.0% (40,111,913 items)\n",
      "Progress: 97.0% (40,529,745 items)\n",
      "Progress: 98.0% (40,947,578 items)\n",
      "Progress: 99.0% (41,365,410 items)\n",
      "────────────────────────────────────────────────────────────\n",
      "RESERVOIR SAMPLING RESULTS\n",
      "────────────────────────────────────────────────────────────\n",
      "Items processed:        41,780,822\n",
      "Metadata entries:       2,420\n",
      "Final sample size:      417,832\n",
      "Execution time:         194.4042 seconds\n",
      "────────────────────────────────────────────────────────────\n",
      "PERFORMANCE METRICS\n",
      "────────────────────────────────────────────────────────────\n",
      "Processing rate:        214,917 items/second\n",
      "Time per item:          4.65 microseconds\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      "Sampling complete: 417,832 samples collected, 154563 unique prefixes\n",
      "\n",
      "Creating 32 work units targeting 1,305,725 records each:\n",
      "  Unit 0: start → 312c3738 (~1,308,800 records)\n",
      "  Unit 1: 312c3738 → 3135343b (~1,305,800 records)\n",
      "  Unit 2: 3135343b → 322e622f (~1,305,800 records)\n",
      "  Unit 3: 322e622f → 332c323a (~1,307,700 records)\n",
      "  Unit 4: 332c323a → 3431302e (~1,306,200 records)\n",
      "  Unit 5: 3431302e → 3539362d (~1,306,100 records)\n",
      "  Unit 6: 3539362d → 37383a33 (~1,305,900 records)\n",
      "  Unit 7: 37383a33 → 412f3838 (~1,305,800 records)\n",
      "  Unit 8: 412f3838 → 42616173 (~1,305,900 records)\n",
      "  Unit 9: 42616173 → 43656e55 (~1,305,900 records)\n",
      "  Unit 10: 43656e55 → 446f646a (~1,305,900 records)\n",
      "  Unit 11: 446f646a → 46757275 (~1,306,100 records)\n",
      "  Unit 12: 46757275 → 49274d43 (~1,305,800 records)\n",
      "  Unit 13: 49274d43 → 4b697475 (~1,306,300 records)\n",
      "  Unit 14: 4b697475 → 4d617343 (~1,305,800 records)\n",
      "  Unit 15: 4d617343 → 4f627573 (~1,305,800 records)\n",
      "  Unit 16: 4f627573 → 50757366 (~1,305,900 records)\n",
      "  Unit 17: 50757366 → 53617677 (~1,305,800 records)\n",
      "  Unit 18: 53617677 → 5465616d (~1,305,900 records)\n",
      "  Unit 19: 5465616d → 57656966 (~1,305,800 records)\n",
      "  Unit 20: 57656966 → 61706f75 (~1,306,200 records)\n",
      "  Unit 21: 61706f75 → 63686971 (~1,305,800 records)\n",
      "  Unit 22: 63686971 → 64697070 (~1,306,100 records)\n",
      "  Unit 23: 64697070 → 66697666 (~1,305,800 records)\n",
      "  Unit 24: 66697666 → 69657375 (~1,305,900 records)\n",
      "  Unit 25: 69657375 → 6c68617a (~1,305,800 records)\n",
      "  Unit 26: 6c68617a → 6e686173 (~1,305,900 records)\n",
      "  Unit 27: 6e686173 → 70687575 (~1,305,800 records)\n",
      "  Unit 28: 70687575 → 72657666 (~1,313,000 records)\n",
      "  Unit 29: 72657666 → 73756273 (~1,306,200 records)\n",
      "  Unit 30: 73756273 → 756e7975 (~1,305,800 records)\n",
      "  Unit 31: 756e7975 → end (~200 records)\n",
      "\n",
      "Created 32 balanced work units\n",
      "Ensured gapless coverage across all work units\n",
      "\n",
      "Work unit balance analysis:\n",
      "  Average: 1,305,725 records per unit\n",
      "  Range: 1,287,900 to 1,313,000\n",
      "  Ratio: 1.0x difference\n",
      "\n",
      "Sorted 32 work units by size (largest first) for optimal parallelization\n",
      "Saved work units to cache: ...orpora/Google_Books/20200217/eng/1gram_files/1grams.db.work_units.json\n",
      "\n",
      "Phase 2: Processing 32 work units with 32 workers...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "    recs scanned     recs written     items kept       throughput       elapsed\n",
      "   ───────────────────────────────────────────────────────────────────────────────\n",
      "    33,592,207       18,272,332       57%              557.5k/s         1m00s         \n",
      "   ──────────────────────────────────── final ────────────────────────────────────\n",
      "    41,783,242       25,127,726       60%              492.2k/s         1m24s         \n",
      "\n",
      "Phase 3: Merging worker outputs into final database...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "Ingesting shards with batch size 128MB / 200,000 items\n",
      "Deleting shards after successful ingestion\n",
      "\n",
      "Folding 32 shard(s) with 32 parallel readers...\n",
      "  unit_0004.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0001.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0000.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0003.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0005.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0002.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0006.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0007.db: 0 items (0.0 MB) [deleted]\n",
      "  unit_0031.db: 395,437 items (736.9 MB) [deleted]\n",
      "  unit_0024.db: 618,826 items (1125.5 MB) [deleted]\n",
      "  unit_0025.db: 612,317 items (1140.0 MB) [deleted]\n",
      "  unit_0023.db: 623,784 items (1187.8 MB) [deleted]\n",
      "  unit_0027.db: 630,747 items (1118.7 MB) [deleted]\n",
      "  unit_0028.db: 639,416 items (1175.7 MB) [deleted]\n",
      "  unit_0029.db: 649,061 items (1192.6 MB) [deleted]\n",
      "  unit_0030.db: 645,717 items (1210.7 MB) [deleted]\n",
      "  unit_0022.db: 652,528 items (1203.4 MB) [deleted]\n",
      "  unit_0026.db: 651,551 items (1138.6 MB) [deleted]\n",
      "  unit_0021.db: 643,935 items (1174.5 MB) [deleted]\n",
      "  unit_0013.db: 716,593 items (1137.1 MB) [deleted]\n",
      "  unit_0020.db: 712,115 items (1204.1 MB) [deleted]\n",
      "  unit_0017.db: 734,142 items (1141.0 MB) [deleted]\n",
      "  unit_0008.db: 738,924 items (1168.4 MB) [deleted]\n",
      "  unit_0011.db: 752,619 items (1224.4 MB) [deleted]\n",
      "  unit_0012.db: 792,056 items (1277.9 MB) [deleted]\n",
      "  unit_0014.db: 814,487 items (1263.0 MB) [deleted]\n",
      "  unit_0016.db: 810,513 items (1284.4 MB) [deleted]\n",
      "  unit_0019.db: 848,935 items (1333.6 MB) [deleted]\n",
      "  unit_0010.db: 846,388 items (1369.4 MB) [deleted]\n",
      "  unit_0015.db: 841,571 items (1281.4 MB) [deleted]\n",
      "  unit_0009.db: 901,919 items (1454.5 MB) [deleted]\n",
      "  unit_0018.db: 930,446 items (1444.5 MB) [deleted]\n",
      "\n",
      "Phase 3: Finalizing (flush)...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "Performing final flush...\n",
      "Running post-ingestion compaction...\n",
      "\n",
      "INCREMENTAL COMPACTION (CACHE-BASED)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "Start Time: 2025-10-06 14:33:29\n",
      "\n",
      "Configuration\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "DB path:           ...t/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams_processed.db\n",
      "Work units file:   1grams.db.work_units.json\n",
      "Estimated keys:    41,783,242\n",
      "Total units:       32\n",
      "Units remaining:   32\n",
      "Checkpoint file:   1grams.db.compaction.checkpoint\n",
      "Initial DB size:   26.51 GB\n",
      "\n",
      "Progress\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[unit_0031      8.8s]:  100%|██████████████████████████████████████████████████| 32/32 [03:14<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incremental Compaction Summary\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Units compacted this run:    32\n",
      "Total units completed:       32/32\n",
      "Size before:                 26.51 GB\n",
      "Size after:                  21.96 GB\n",
      "Space saved:                 4.54 GB (17.1%)\n",
      "Total runtime:               0:03:14\n",
      "Time per unit:               0:00:06\n",
      "Units per hour:              591.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 4: Generating output whitelist...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Output path: ...LP_corpora/Google_Books/20200217/eng/1gram_files/1grams_processed.db/whitelist.txt\n",
      "  Extracting top 40,000 tokens\n",
      "  Generated whitelist with 40,000 tokens in 145.8s\n",
      "\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ PROCESSING COMPLETE: Final DB contains 17,204,027 items, 29,263.7 MB                  │\n",
      "│ DB: ...t/edk202/NLP_corpora/Google_Books/20200217/eng/1gram_files/1grams_processed.db │\n",
      "│ Whitelist: ...Google_Books/20200217/eng/1gram_files/1grams_processed.db/whitelist.txt │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T18:39:10.328466Z",
     "start_time": "2025-10-06T18:39:10.325929Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f9ca933e73eda985",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist_w2v (Singularity)",
   "language": "python",
   "name": "hist_w2v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
