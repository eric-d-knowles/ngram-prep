{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:31:54.098025Z",
     "start_time": "2025-09-14T20:31:45.135032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /scratch/edk202/ngram-prep\n",
    "\n",
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "\n",
    "%pip install -e . --no-build-isolation -q"
   ],
   "id": "1ad267332e4b1fcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/edk202/ngram-prep\n",
      "env: LC_ALL=C.UTF-8\n",
      "env: LANG=C.UTF-8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:45:22.796141Z",
     "start_time": "2025-09-14T20:45:22.768126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auto-reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "ad3fc5fc588e8363",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:45:23.997809Z",
     "start_time": "2025-09-14T20:45:23.262330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard stuff\n",
    "from pathlib import Path\n",
    "\n",
    "# NLTK stuff\n",
    "from nltk.corpus import stopwords; stopwords = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import WordNetLemmatizer; lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Raw n-gram acquisition stuff\n",
    "from ngram_acquire.pipeline.orchestrate import download_and_ingest_to_rocksdb\n",
    "from ngram_acquire.pipeline.logger import setup_logger\n",
    "\n",
    "# Cython utilities\n",
    "from ngram_filter.config import PipelineConfig, FilterConfig\n",
    "from ngram_filter.pipeline.orchestrator import build_processed_db"
   ],
   "id": "be55f147a8e96bcf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:45:26.502176Z",
     "start_time": "2025-09-14T20:45:26.437606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "setup_logger(\n",
    "    db_path=\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\",\n",
    "    console=False,\n",
    "    rotate=True,\n",
    "    max_bytes=100_000_000,\n",
    "    backup_count=5,\n",
    "    force=True\n",
    ")"
   ],
   "id": "5b072e6dbd0ce17c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db/ngram_download_20250914_164526.log')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download Unigrams and Ingest to a RocksDB Database",
   "id": "fe5d0309548b386a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T04:46:19.004663Z",
     "start_time": "2025-09-13T04:36:35.442405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_and_ingest_to_rocksdb(\n",
    "    ngram_size = 1,\n",
    "    repo_release_id = \"20200217\",\n",
    "    repo_corpus_id = \"eng\",\n",
    "    db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\",\n",
    "    file_range = (0, 23),\n",
    "    random_seed = 21,\n",
    "    workers = 25,\n",
    "    use_threads = False,\n",
    "    ngram_type = \"tagged\",\n",
    "    overwrite = True,\n",
    "    write_batch_size = 100_000,\n",
    "    open_type = \"write:packed24\",\n",
    "    post_compact = False\n",
    ")"
   ],
   "id": "9f25804d1183f1fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mStart Time: 2025-09-13 00:36:35\u001B[0m\n",
      "\u001B[4m\n",
      "Download & Ingestion Configuration\u001B[0m\n",
      "Ngram repository:           https://storage.googleapis.com/books/ngrams/books/20200217/eng/eng-1-ngrams_exports.html\n",
      "RocksDB database path:      /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\n",
      "File index range:           0 to 23 (count ~ 24)\n",
      "Total files available:      24\n",
      "Files to process:           24\n",
      "First file URL:             http://storage.googleapis.com/books/ngrams/books/20200217/eng/1-00012-of-00024.gz\n",
      "Last file URL:              http://storage.googleapis.com/books/ngrams/books/20200217/eng/1-00005-of-00024.gz\n",
      "Ngram size:                 1\n",
      "Ngram filtering:            tagged\n",
      "Overwrite mode:             True\n",
      "Write batch size:           100,000\n",
      "Worker processes/threads:   25 (processes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|\u001B[34m██████████\u001B[0m| 24/24 [09:37<00:00, 24.06s/files]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m\n",
      "Processing completed!\u001B[0m\n",
      "Fully processed files: 24\n",
      "Total entries written: 41,783,218\n",
      "Write batches flushed: 24\n",
      "Uncompressed data processed: 43.28 GB\n",
      "Processing throughput: 75.95 MB/sec\n",
      "\u001B[31m\n",
      "End Time: 2025-09-13 00:46:18.998858\u001B[0m\n",
      "\u001B[31mTotal Runtime: 0:09:43.512893\u001B[0m\n",
      "\u001B[34m\n",
      "Time per file: 0:00:24.313037\u001B[0m\n",
      "\u001B[34mFiles per hour: 148.1\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Processing Pipeline",
   "id": "97d09d26c6f2043f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:59:28.317621Z",
     "start_time": "2025-09-14T20:45:33.943011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_db = Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\")\n",
    "dst_db = src_db.parent / \"1grams_processed.db\"\n",
    "tmp_dir = src_db.parent / \"processing_tmp\"\n",
    "\n",
    "# Default configs or override as desired\n",
    "pipeline_config = PipelineConfig(\n",
    "    src_db=src_db,\n",
    "    dst_db=dst_db,\n",
    "    tmp_dir=tmp_dir,\n",
    "    readers=8,\n",
    "    force_restart=True,\n",
    "    progress_every_s=60.0,\n",
    "    output_whitelist_path=dst_db / \"whitelist.txt\",\n",
    "    output_whitelist_top_n=60_000\n",
    ")\n",
    "\n",
    "filter_config = FilterConfig(\n",
    "    stop_set=stopwords,\n",
    "    lemma_gen=lemmatizer,\n",
    ")\n",
    "\n",
    "build_processed_db(pipeline_config, filter_config)"
   ],
   "id": "57db436f73cba01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM FILTER PIPELINE\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      "Configuration:\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Workers: 8\n",
      "  Work units: 64\n",
      "  Source: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\n",
      "  Destination: 02/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams_processed.db\n",
      "  Buffer: 25,000 items, 16MB\n",
      "  Profile: write:packed24\n",
      "  Input whitelist: None\n",
      "  Output whitelist: .../20200217/eng/5gram_files/1grams_processed.db/whitelist.txt (top 60,000 keys)\n",
      "\n",
      "Phase 1: Creating work units...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Force restart requested - clearing existing work units\n",
      "  Creating 64 work units using ASCII range...\n",
      "  Created 64 work units covering range 0x21-0x7e\n",
      "  Validating 64 work units...\n",
      "  Validated 64 work units: 795 keys over 10 sample units\n",
      "  Created 64 work units\n",
      "\n",
      "Phase 2: Processing 64 work units with 8 workers...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "    recs scanned   recs written   items kept     throughput     elapsed\n",
      "   ─────────────────────────────────────────────────────────────────────\n",
      "    34,309         0              0%             571/s          1m00s       \n",
      "    8,883,442      0              0%             74.0k/s        2m00s       \n",
      "    14,688,249     3,422,094      23%            81.6k/s        3m00s       \n",
      "    23,916,038     11,201,339     47%            99.6k/s        4m00s       \n",
      "    28,341,813     14,837,471     52%            94.4k/s        5m00s       \n",
      "    37,491,492     22,060,345     59%            104.1k/s       6m00s       \n",
      "   ──────────────────────────────  final  ──────────────────────────────\n",
      "    41,783,242     25,133,088     60%            105.0k/s       6m38s       \n",
      "\n",
      "Phase 3: Merging worker outputs into final database...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Found 64 worker output files\n",
      "  Batch size: 64MB, 100,000 items\n",
      "  Folding 64 shard(s)...\n",
      "  unit_0000.db: 0 items (0.0 MB)\n",
      "  unit_0001.db: 0 items (0.0 MB)\n",
      "  unit_0002.db: 0 items (0.0 MB)\n",
      "  unit_0003.db: 0 items (0.0 MB)\n",
      "  unit_0004.db: 0 items (0.0 MB)\n",
      "  unit_0005.db: 0 items (0.0 MB)\n",
      "  unit_0006.db: 0 items (0.0 MB)\n",
      "  unit_0007.db: 0 items (0.0 MB)\n",
      "  unit_0008.db: 0 items (0.0 MB)\n",
      "  unit_0009.db: 0 items (0.0 MB)\n",
      "  unit_0010.db: 0 items (0.0 MB)\n",
      "  unit_0011.db: 0 items (0.0 MB)\n",
      "  unit_0012.db: 0 items (0.0 MB)\n",
      "  unit_0013.db: 0 items (0.0 MB)\n",
      "  unit_0014.db: 0 items (0.0 MB)\n",
      "  unit_0015.db: 0 items (0.0 MB)\n",
      "  unit_0016.db: 0 items (0.0 MB)\n",
      "  unit_0017.db: 0 items (0.0 MB)\n",
      "  unit_0018.db: 0 items (0.0 MB)\n",
      "  unit_0019.db: 0 items (0.0 MB)\n",
      "  unit_0020.db: 0 items (0.0 MB)\n",
      "  unit_0021.db: 0 items (0.0 MB)\n",
      "  unit_0022.db: 609,457 items (971.1 MB)\n",
      "  unit_0023.db: 609,958 items (994.6 MB)\n",
      "  unit_0024.db: 1,151,958 items (1874.2 MB)\n",
      "  unit_0025.db: 334,227 items (546.4 MB)\n",
      "  unit_0026.db: 681,582 items (1095.3 MB)\n",
      "  unit_0027.db: 403,808 items (661.4 MB)\n",
      "  unit_0028.db: 464,355 items (777.7 MB)\n",
      "  unit_0029.db: 399,111 items (569.8 MB)\n",
      "  unit_0030.db: 1,025,908 items (1641.3 MB)\n",
      "  unit_0031.db: 281,786 items (410.5 MB)\n",
      "  unit_0032.db: 228,718 items (361.2 MB)\n",
      "  unit_0033.db: 684,296 items (1086.1 MB)\n",
      "  unit_0034.db: 369,750 items (598.0 MB)\n",
      "  unit_0035.db: 1,381,405 items (2166.3 MB)\n",
      "  unit_0036.db: 127,271 items (195.9 MB)\n",
      "  unit_0037.db: 479,188 items (777.1 MB)\n",
      "  unit_0038.db: 26,595 items (39.1 MB)\n",
      "  unit_0039.db: 155,798 items (220.8 MB)\n",
      "  unit_0040.db: 0 items (0.0 MB)\n",
      "  unit_0041.db: 0 items (0.0 MB)\n",
      "  unit_0042.db: 0 items (0.0 MB)\n",
      "  unit_0043.db: 0 items (0.0 MB)\n",
      "  unit_0044.db: 538,284 items (994.6 MB)\n",
      "  unit_0045.db: 286,776 items (510.1 MB)\n",
      "  unit_0046.db: 974,744 items (1797.5 MB)\n",
      "  unit_0047.db: 345,354 items (656.4 MB)\n",
      "  unit_0048.db: 459,255 items (864.1 MB)\n",
      "  unit_0049.db: 238,973 items (422.3 MB)\n",
      "  unit_0050.db: 431,502 items (842.8 MB)\n",
      "  unit_0051.db: 94,267 items (139.5 MB)\n",
      "  unit_0052.db: 672,629 items (1196.1 MB)\n",
      "  unit_0053.db: 231,551 items (404.7 MB)\n",
      "  unit_0054.db: 286,040 items (515.7 MB)\n",
      "  unit_0055.db: 612,066 items (1084.0 MB)\n",
      "  unit_0056.db: 350,019 items (675.6 MB)\n",
      "  unit_0057.db: 1,051,268 items (1926.3 MB)\n",
      "  unit_0058.db: 157,200 items (310.7 MB)\n",
      "  unit_0059.db: 277,494 items (529.7 MB)\n",
      "  unit_0060.db: 15,083 items (27.3 MB)\n",
      "  unit_0061.db: 63,061 items (104.6 MB)\n",
      "  unit_0062.db: 0 items (0.0 MB)\n",
      "  unit_0063.db: 0 items (0.0 MB)\n",
      "\n",
      "Phase 3: Finalizing...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Performing final flush...\n",
      "  Compacting...\n",
      "\n",
      "Phase 4: Generating output whitelist...\n",
      "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
      "  Output path: .../Google_Books/20200217/eng/5gram_files/1grams_processed.db/whitelist.txt\n",
      "  Extracting top 60,000 tokens\n",
      "  Generated whitelist with 60,000 tokens in 126.3s\n",
      "\n",
      "╭─────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ PROCESSING COMPLETE: Final DB contains 16,500,737 items, 27,988.6 MB                │\n",
      "│ DB: ...02/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams_processed.db     │\n",
      "│ Whitelist: ...Books/20200217/eng/5gram_files/1grams_processed.db/whitelist.txt      │\n",
      "╰─────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63ca9560fef8472d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist_w2v (Singularity)",
   "language": "python",
   "name": "hist_w2v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
