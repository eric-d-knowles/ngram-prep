{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Setup**\n",
    "## Imports"
   ],
   "id": "ed15de79ff6600a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T21:16:29.698688Z",
     "start_time": "2025-10-08T21:16:29.665502Z"
    }
   },
   "cell_type": "code",
   "source": "# Auto-reload edited scripts\n%load_ext autoreload\n%autoreload 2\n\n# Logging\nfrom ngram_prep.ngram_acquire.logger import setup_logger\n\n# Ngram pivot functions\nfrom pathlib import Path\nfrom ngram_prep.ngram_pivot.config import PivotConfig\nfrom ngram_prep.ngram_pivot.parallel import pivot_parallel, ParallelPivotConfig\nfrom ngram_prep.ngram_pivot.merge import merge_pivot_shards\n\n# Utilities\nfrom ngram_prep.utilities.peek import *",
   "id": "ce854c30d3ed2553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up logging to file",
   "id": "9dcc445498bb0c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T21:16:30.632844Z",
     "start_time": "2025-10-08T21:16:30.545146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "setup_logger(\n",
    "    db_path=\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_pivoted.db\",\n",
    "    console=False,\n",
    "    rotate=True,\n",
    "    max_bytes=100_000_000,\n",
    "    backup_count=5,\n",
    "    force=True\n",
    ")"
   ],
   "id": "12e3d73b8a010aa3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/ngram_download_20251008_171630.log')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Pivot Multigrams to Create Yearly Indices**",
   "id": "3c54b7932d2716a8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-08T21:18:44.299337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure and run the pivot operation\n",
    "pivot_cfg = PivotConfig(\n",
    "    source_db_path=Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_processed.db\"),\n",
    "    target_db_path=Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_pivoted.db\"),\n",
    "    write_batch_size=100_000,\n",
    "    validate=True\n",
    ")\n",
    "\n",
    "parallel_cfg = ParallelPivotConfig(\n",
    "    num_workers=40,\n",
    "    mode=\"restart\"\n",
    ")\n",
    "\n",
    "shards_dir = pivot_parallel(pivot_cfg, parallel_cfg)\n",
    "\n",
    "total_items, total_bytes = merge_pivot_shards(\n",
    "    shards_dir=shards_dir,\n",
    "    target_db_path=pivot_cfg.target_db_path,\n",
    "    num_readers=40,\n",
    "    delete_shards=True,\n",
    ")"
   ],
   "id": "43b7bbb5c1414fd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARALLEL N-GRAM DATABASE PIVOT\n",
      "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
      "Start Time: 2025-10-08 17:18:44\n",
      "Mode:       RESTART\n",
      "\n",
      "Configuration\n",
      "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
      "Workers:              40\n",
      "Work units:           320\n",
      "Dynamic splitting:    enabled\n",
      "Sample rate:          0.001\n",
      "Prefix length:        2\n",
      "Write batch size:     100,000\n",
      "Source profile:       read:packed24\n",
      "Target profile:       write:packed24\n",
      "\n",
      "Phase 1: Creating work units...\n",
      "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
      "Using cache from 5grams.db for 5grams_processed.db\n",
      "Forcing cache use and not checking config match\n",
      "Loaded 107 work units from cache\n",
      "\n",
      "Phase 2: Processing 107 pending work units with 40 workers...\n",
      "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [  917.1M recs]:  |\u2588                             | 21.6M/577M [01:22<32:04, 289kngram/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0029.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0029.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [  939.5M recs]:  |\u2588\u258f                            | 22.1M/577M [01:24<32:24, 286kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0044_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0044_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [    1.2B recs]:  |\u2588\u258d                            | 28.8M/577M [02:01<53:34, 171kngram/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> <UNK> average tariff': IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L.db/000008.sst: No such file or directory\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [    1.2B recs]:  |\u2588\u258c                            | 29.5M/577M [02:05<49:46, 183kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'delicate nose <UNK> <UNK> profusion': IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0044_L.db/000008.sst: No such file or directory\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0044_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0044_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   11.0B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 234M/577M [17:37<31:13, 184kngram/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_L_L_R_R_R_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_L_L_R_R_R_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   15.5B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e             | 314M/577M [24:36<20:06, 218kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_L_R_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_L_R_L_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   18.1B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b           | 361M/577M [28:42<19:16, 187kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_R_L_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_R_L_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   18.4B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           | 367M/577M [29:11<17:17, 203kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_R_L_R_R_L_R_R_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_L_R_R_R_L_R_R_L_R_R_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   19.2B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 381M/577M [30:23<17:10, 191kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_L_L_R_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_L_L_R_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   19.9B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 394M/577M [31:32<17:22, 176kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   21.4B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 422M/577M [33:54<12:01, 215kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_L_L_L_R_L_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_L_L_L_R_L_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   21.5B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 423M/577M [33:59<12:15, 210kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_L_L_L_R_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_L_R_L_L_L_R_L_L_L_L_L_R_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   24.1B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 475M/577M [38:06<07:13, 238kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_R_R_R_R_R_R_R_R_L_L_R_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0026_R_R_R_R_R_R_R_R_R_R_L_L_R_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   24.4B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 481M/577M [38:34<07:25, 217kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_L_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   24.8B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 488M/577M [39:09<07:34, 196kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_L_R_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_L_R_L_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   25.2B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 495M/577M [39:46<06:19, 216kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_R_R_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_L_R_R_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   26.3B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 518M/577M [41:33<04:34, 215kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_L_L_L_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_L_L_L_L_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   26.7B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 525M/577M [42:05<04:11, 208kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_R_L_L_L_L_R_R_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_R_L_L_L_L_R_R_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   27.4B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 540M/577M [43:18<03:26, 181kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_R_L_L_L_L_R_R_R_L_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_L_L_L_L_L_R_L_L_L_L_R_R_R_L_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   27.8B recs]:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 547M/577M [43:52<02:30, 204kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_L_L_L_L_R_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_L_L_L_L_R_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   29.7B recs]:  |                              | 584M/? [46:46<00:00, 218kngram/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_R_R_R_R_R_L_L_R_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_R_R_R_R_R_L_L_R_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   30.0B recs]:  |                              | 590M/? [47:22<00:00, 209kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_R_R_R_R_R_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_L_R_R_R_R_R_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   31.5B recs]:  |                              | 619M/? [49:39<00:00, 222kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_L_R_R_R_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_L_R_R_R_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   32.2B recs]:  |                              | 634M/? [50:53<00:00, 193kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_R_L_L_L_L_R_L_R_L_L_R_L_R_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_L_R_R_L_L_L_L_R_L_R_L_L_R_L_R_L_R_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.1B recs]:  |                              | 671M/? [53:48<00:00, 206kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_R_L_R_L_L_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_R_L_R_L_L_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.1B recs]:  |                              | 671M/? [53:49<00:00, 200kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_R_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_R_L_R_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.2B recs]:  |                              | 672M/? [53:55<00:00, 176kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_L_R_L_R_L_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_L_R_L_L_L_L_R_L_L_L_L_R_L_R_L_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.5B recs]:  |                              | 679M/? [54:25<00:00, 195kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_L_R_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_L_R_L.db/000008.sst: No such file or directory\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R.db/000008.sst: No such file or directory\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:55<00:00, 186kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 178, in _process_work_unit_shard\n",
      "    with open_db(\n",
      "  File \"/ext3/miniforge3/envs/hist_w2v/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/common_db/api.py\", line 47, in open_db\n",
      "    db = rs.open(str(path), mode=mode, **kwargs)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_L.db: Disk quota exceeded\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:55<00:00, 186kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L.db: IO error: While pwrite to file at offset 20971520: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L.db/000008.sst: Disk quota exceeded\n",
      "Worker 27 failed on unit unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_L: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_L.db: Disk quota exceeded\n",
      "Worker 27 crashed: disk I/O error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 178, in _process_work_unit_shard\n",
      "    with open_db(\n",
      "  File \"/ext3/miniforge3/envs/hist_w2v/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/common_db/api.py\", line 47, in open_db\n",
      "    db = rs.open(str(path), mode=mode, **kwargs)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_L.db: Disk quota exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 144, in pivot_worker\n",
      "    work_tracker.fail_work_unit(work_unit.unit_id)\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 212, in fail_work_unit\n",
      "    conn.commit()\n",
      "sqlite3.OperationalError: disk I/O error\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:56<00:00, 179kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 178, in _process_work_unit_shard\n",
      "    with open_db(\n",
      "  File \"/ext3/miniforge3/envs/hist_w2v/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/common_db/api.py\", line 47, in open_db\n",
      "    db = rs.open(str(path), mode=mode, **kwargs)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_R.db: Disk quota exceeded\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:56<00:00, 191kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> consistency <UNK> ought': IO error: While pwrite to file at offset 883949568: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R.db/000035.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R.db: IO error: While pwrite to file at offset 883949568: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R.db/000035.sst: Disk quota exceeded\n",
      "Worker 13 failed on unit unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_R: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_L_R.db: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 128, in claim_work_unit\n",
      "    with sqlite3.connect(str(self.db_path)) as conn:\n",
      "sqlite3.OperationalError: disk I/O error\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:56<00:00, 187kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> critical body composition': IO error: While pwrite to file at offset 849346560: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L.db/000037.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L.db: IO error: While pwrite to file at offset 849346560: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L.db/000037.sst: Disk quota exceeded\n",
      "Worker 13 crashed: disk I/O error\n",
      "Error processing n-gram b'<UNK> <UNK> consist <UNK> open': IO error: While pwrite to file at offset 848297984: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L.db/000035.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L.db: IO error: While pwrite to file at offset 848297984: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L.db/000035.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:57<00:00, 206kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> criminal statute even': IO error: While pwrite to file at offset 769654784: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R.db/000037.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R.db: IO error: While pwrite to file at offset 769654784: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R.db/000037.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:57<00:00, 191kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:57<00:00, 202kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 20 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:57<00:00, 190kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 201kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> coffin <UNK> force': IO error: While pwrite to file at offset 761266176: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R.db/000033.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R.db: IO error: While pwrite to file at offset 761266176: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R.db/000033.sst: Disk quota exceeded\n",
      "Worker 38 crashed: unable to open database file\n",
      "Worker 37 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 195kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 178, in _process_work_unit_shard\n",
      "    with open_db(\n",
      "  File \"/ext3/miniforge3/envs/hist_w2v/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/common_db/api.py\", line 47, in open_db\n",
      "    db = rs.open(str(path), mode=mode, **kwargs)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R_L.db: Disk quota exceeded\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 197kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> competition make obligatory': IO error: While pwrite to file at offset 889192448: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R.db: IO error: While pwrite to file at offset 889192448: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L.db: IO error: While pwrite to file at offset 75497472: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L.db/000008.sst: Disk quota exceeded\n",
      "Worker 7 failed on unit unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R_L: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R_L.db: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 197kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 178, in _process_work_unit_shard\n",
      "    with open_db(\n",
      "  File \"/ext3/miniforge3/envs/hist_w2v/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/common_db/api.py\", line 47, in open_db\n",
      "    db = rs.open(str(path), mode=mode, **kwargs)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: IO error: While mkdir if missing: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R_L.db: Disk quota exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 144, in pivot_worker\n",
      "    work_tracker.fail_work_unit(work_unit.unit_id)\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 204, in fail_work_unit\n",
      "    conn.execute(\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 197kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 7 crashed: unable to open database file\n",
      "Error processing n-gram b'<UNK> <UNK> double <UNK> large': IO error: While pwrite to file at offset 695205888: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R.db/000041.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R.db: IO error: While pwrite to file at offset 695205888: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R.db/000041.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R.db/000008.sst: Disk quota exceeded\n",
      "Error processing n-gram b'<UNK> <UNK> competent natural enemy': IO error: While pwrite to file at offset 702545920: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L.db: IO error: While pwrite to file at offset 702545920: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L.db/000034.sst: Disk quota exceeded\n",
      "Error processing n-gram b'<UNK> <UNK> criminal case prosecute': IO error: While pwrite to file at offset 837812224: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L.db/000037.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L.db: IO error: While pwrite to file at offset 837812224: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L.db/000037.sst: Disk quota exceeded\n",
      "Error processing n-gram b'<UNK> <UNK> competition <UNK> exchange': IO error: While pwrite to file at offset 687865856: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R.db/000034.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 178kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R.db: IO error: While pwrite to file at offset 687865856: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R.db/000034.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:58<00:00, 191kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 181kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 23 crashed: unable to open database file\n",
      "Error processing n-gram b'<UNK> <UNK> competent <UNK> therefore': IO error: While pwrite to file at offset 827326464: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R.db: IO error: While pwrite to file at offset 827326464: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L.db/000008.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 181kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 167kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 5 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 167kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 159kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 33 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [54:59<00:00, 137kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 24 crashed: unable to open database file\n",
      "Worker 12 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:00<00:00, 146kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:00<00:00, 146kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_L_R_R_R_L_L_L_R_L_R.db/000008.sst: Disk quota exceeded\n",
      "Worker 31 crashed: unable to open database file\n",
      "Worker 3 crashed: unable to open database file\n",
      "Worker 8 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:00<00:00, 130kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:00<00:00, 140kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 6 crashed: unable to open database file\n",
      "Worker 26 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:00<00:00, 134kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 4 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 685M/? [55:01<00:00, 140kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.8B recs]:  |                              | 686M/? [55:01<00:00, 136kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.8B recs]:  |                              | 686M/? [55:01<00:00, 129kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> doctor <UNK> represent': IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L.db/000041.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L.db/000041.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:02<00:00, 134kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> endless vortex <UNK>': IO error: While pwrite to file at offset 538968064: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007.db/000043.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007.db: IO error: While pwrite to file at offset 538968064: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007.db/000043.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:02<00:00, 131kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:03<00:00, 127kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 2 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:03<00:00, 123kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:04<00:00, 128kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 25 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:05<00:00, 130kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> democratic member <UNK>': IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R.db/000039.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R.db/000039.sst: Disk quota exceeded\n",
      "Error processing n-gram b'<UNK> <UNK> communist act <UNK>': IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db/000034.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db/000034.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:06<00:00, 132kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 686M/? [55:07<00:00, 132kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 28 crashed: unable to open database file\n",
      "Worker 17 failed on unit unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db/000034.sst: Disk quota exceeded\n",
      "Worker 17 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 211, in _process_work_unit_shard\n",
      "    _flush_batch(target_db, write_buffer, stats, target_counter)\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 232, in _flush_batch\n",
      "    with db.write_batch(disable_wal=True, sync=False) as batch:\n",
      "RuntimeError: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db/000034.sst: Disk quota exceeded\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 120, in pivot_worker\n",
      "    _process_work_unit_shard(\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 211, in _process_work_unit_shard\n",
      "    _flush_batch(target_db, write_buffer, stats, target_counter)\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 232, in _flush_batch\n",
      "    with db.write_batch(disable_wal=True, sync=False) as batch:\n",
      "RuntimeError: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R_L_R_L_L_L_L_R_R_R_L_R_L.db/000034.sst: Disk quota exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 144, in pivot_worker\n",
      "    work_tracker.fail_work_unit(work_unit.unit_id)\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 204, in fail_work_unit\n",
      "    conn.execute(\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 687M/? [55:10<00:00, 130kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> convert <UNK> subdue': IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R.db/000036.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L_R_R_R_L_L_R_L_R_L_R.db/000036.sst: Disk quota exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 687M/? [55:11<00:00, 121kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 687M/? [55:11<00:00, 120kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing n-gram b'<UNK> <UNK> democratic member <UNK>': IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L.db/000039.sst: Disk quota exceeded\n",
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L.db: IO error: While open a file for appending: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0007_L_R_L_L_L.db/000039.sst: Disk quota exceeded\n",
      "Worker 30 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   34.9B recs]:  |                              | 687M/? [55:13<00:00, 104kngram/s]Traceback (most recent call last):\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/parallel.py\", line 109, in pivot_worker\n",
      "    work_unit = work_tracker.claim_work_unit(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/edk202/ngram-prep/src/ngram_pivot/work_tracker.py\", line 131, in claim_work_unit\n",
      "    cursor = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "Pivoting [   34.9B recs]:  |                              | 687M/? [55:13<00:00, 103kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 1 crashed: unable to open database file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   35.6B recs]:  |                              | 700M/? [57:40<00:00, 79.2kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_R_L_R_R_L_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0027_R_R_R_R_R_R_R_R_L_R_R_L_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   36.3B recs]:  |                              | 713M/? [1:00:02<00:00, 79.8kngram/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Database flush failed for /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0028_L_L_L_L_L_L_L_L_L_L_L_L_L_L.db: IO error: No such file or directory: While open a file for random read: /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/pivot_tmp/shards/unit_0028_L_L_L_L_L_L_L_L_L_L_L_L_L_L.db/000008.sst: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pivoting [   36.3B recs]:  |                              | 713M/? [1:00:04<00:00, 76.2kngram/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Inspect the Procesed Database**\n",
    "## `db_head`: Print the first _N_ key\u2013value pairs"
   ],
   "id": "b916bcb8f52efc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:44:54.857648Z",
     "start_time": "2025-10-07T15:44:50.387247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_processed.db\"\n",
    "\n",
    "db_head(db_path, key_format=\"utf-8\", value_format=\"packed\", n=5)"
   ],
   "id": "602ef9dec8103212",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 key-value pairs:\n",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
      "[ 1] Key:   <UNK> <UNK> <UNK> <UNK> aaa\n",
      "     Value: [166 records] ... +156 earlier, (2010, 471, 403), (2011, 413, 327), (2012, 362, 299)\n",
      "            (2013, 267, 224), (2014, 309, 256), (2015, 220, 190), (2016, 232, 204)\n",
      "            (2017, 194, 184), (2018, 132, 107), (2019, 139, 115)\n",
      "\n",
      "[ 2] Key:   <UNK> <UNK> <UNK> <UNK> aac\n",
      "     Value: [122 records] ... +112 earlier, (2010, 124, 103), (2011, 131, 97), (2012, 138, 114)\n",
      "            (2013, 178, 87), (2014, 176, 134), (2015, 58, 53), (2016, 96, 86), (2017, 121, 74)\n",
      "            (2018, 115, 74), (2019, 29, 27)\n",
      "\n",
      "[ 3] Key:   <UNK> <UNK> <UNK> <UNK> aachen\n",
      "     Value: [143 records] ... +133 earlier, (2010, 216, 152), (2011, 235, 173), (2012, 1900, 1363)\n",
      "            (2013, 1181, 944), (2014, 223, 169), (2015, 132, 120), (2016, 207, 162)\n",
      "            (2017, 257, 141), (2018, 192, 140), (2019, 144, 121)\n",
      "\n",
      "[ 4] Key:   <UNK> <UNK> <UNK> <UNK> aad\n",
      "     Value: [49 records] ... +39 earlier, (2010, 16, 15), (2011, 32, 21), (2012, 49, 41), (2013, 36, 32)\n",
      "            (2014, 27, 21), (2015, 16, 15), (2016, 20, 17), (2017, 27, 24), (2018, 41, 28)\n",
      "            (2019, 24, 21)\n",
      "\n",
      "[ 5] Key:   <UNK> <UNK> <UNK> <UNK> aaf\n",
      "     Value: [84 records] ... +74 earlier, (2010, 45, 37), (2011, 57, 45), (2012, 629, 319), (2013, 291, 181)\n",
      "            (2014, 61, 57), (2015, 49, 45), (2016, 69, 51), (2017, 34, 27), (2018, 56, 36)\n",
      "            (2019, 84, 43)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## `db_peek`: Print _N_ key-value pairs starting at the specified key",
   "id": "a5cd2b4c5b2bef6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:45:03.799144Z",
     "start_time": "2025-10-07T15:45:01.919493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_processed.db\"\n",
    "\n",
    "db_peek(db_path, start_key=b\"quick brown <UNK> <UNK> <UNK>\", key_format=\"utf-8\", value_format=\"packed\", n=5)\n"
   ],
   "id": "4ae0c4f82ae61dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 key-value pairs starting from 717569636b2062726f776e203c554e4b3e203c554e4b3e203c554e4b3e:\n",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
      "[ 1] Key:   quick brown <UNK> <UNK> <UNK>\n",
      "     Value: [21 records] ... +11 earlier, (2006, 4, 3), (2007, 1, 1), (2008, 13, 3), (2009, 2, 2)\n",
      "            (2010, 5, 4), (2011, 2, 2), (2012, 9, 7), (2013, 5, 3), (2014, 2, 1), (2016, 1, 1)\n",
      "\n",
      "[ 2] Key:   quick brown eye <UNK> <UNK>\n",
      "     Value: [156 records] ... +146 earlier, (2010, 5, 5), (2011, 6, 6), (2012, 10, 10), (2013, 19, 19)\n",
      "            (2014, 18, 18), (2015, 22, 22), (2016, 18, 18), (2017, 26, 26), (2018, 99, 99)\n",
      "            (2019, 16, 16)\n",
      "\n",
      "[ 3] Key:   quick brown eye <UNK> butler\n",
      "     Value: [10 records] (1866, 23, 23), (1867, 2, 2), (1869, 2, 2), (1870, 2, 2), (1871, 4, 4), (1875, 3, 3)\n",
      "            (1891, 1, 1), (1892, 1, 1), (1903, 1, 1), (1908, 1, 1)\n",
      "\n",
      "[ 4] Key:   quick brown eye take <UNK>\n",
      "     Value: [36 records] ... +26 earlier, (2007, 1, 1), (2008, 9, 9), (2009, 1, 1), (2011, 2, 2), (2012, 3, 3)\n",
      "            (2013, 1, 1), (2014, 1, 1), (2015, 1, 1), (2018, 2, 2), (2019, 5, 5)\n",
      "\n",
      "[ 5] Key:   quick brown fox <UNK> <UNK>\n",
      "     Value: [74 records] ... +64 earlier, (2010, 86, 45), (2011, 19, 18), (2012, 75, 42), (2013, 69, 35)\n",
      "            (2014, 61, 33), (2015, 85, 26), (2016, 58, 35), (2017, 56, 22), (2018, 45, 20)\n",
      "            (2019, 7, 6)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## `db_peek_prefix`: Print key-value pairs containing the specified prefix",
   "id": "f0261bc901193643"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:49:48.574130Z",
     "start_time": "2025-10-07T15:49:47.054355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams_processed.db\"\n",
    "\n",
    "db_peek_prefix(db_path, prefix=b\"<UNK> united state <UNK> <UNK>\", key_format=\"utf-8\", value_format=\"summary\", n=1)"
   ],
   "id": "b04a9e9cf0cc209f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 key-value pairs with prefix 3c554e4b3e20756e69746564207374617465203c554e4b3e203c554e4b3e:\n",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
      "[ 1] Key:   <UNK> united state <UNK> <UNK>\n",
      "     Value: Total: 163,384,713 occurrences in 96,901,345 volumes (1472-2019, 384 years)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35abdd0e1baea1b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist_w2v (Singularity)",
   "language": "python",
   "name": "hist_w2v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}