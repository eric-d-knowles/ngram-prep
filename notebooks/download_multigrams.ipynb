{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T13:55:05.358103Z",
     "start_time": "2025-09-09T13:54:56.257654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%cd /scratch/edk202/ngram-prep\n",
    "\n",
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "\n",
    "%pip install -e . --no-build-isolation -q"
   ],
   "id": "e2b29f8010b30c2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/edk202/ngram-prep\n",
      "env: LC_ALL=C.UTF-8\n",
      "env: LANG=C.UTF-8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T13:55:05.389563Z",
     "start_time": "2025-09-09T13:55:05.361838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auto-reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "ce854c30d3ed2553",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T13:55:06.137995Z",
     "start_time": "2025-09-09T13:55:05.407341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard stuff\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# NLTK stuff\n",
    "from nltk.corpus import stopwords; stopwords = set(stopwords.words(\"english\"))\n",
    "from nltk.stem import WordNetLemmatizer; lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Raw n-gram acquisition stuff\n",
    "from ngram_acquire.pipeline.orchestrate import download_and_ingest_to_rocksdb\n",
    "from ngram_acquire.pipeline.logger import setup_logger\n",
    "from utilities.save_sample import save_sample_to_db, verify_sample_db\n",
    "\n",
    "# Downloaded n-gram filtering stuff\n",
    "from ngram_filter import PipelineConfig, FilterConfig\n",
    "from ngram_filter.pipeline.old.orchestrator import build_processed_db_sharded\n",
    "\n",
    "# Cython utilities\n",
    "from utilities.count_items import count_db_items\n",
    "from utilities.reservoir_sampler import reservoir_sampling"
   ],
   "id": "66bfa7710298d111",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T13:55:06.202561Z",
     "start_time": "2025-09-09T13:55:06.142090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "setup_logger(\n",
    "    db_path=\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db\",\n",
    "    console=False,\n",
    "    rotate=True,\n",
    "    max_bytes=100_000_000,\n",
    "    backup_count=5,\n",
    "    force=True\n",
    ")"
   ],
   "id": "fd41f453d3936ce3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams.db/ngram_download_20250909_095506.log')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Download 5-Grams and Ingest to a RocksDB Database**",
   "id": "51b58f57597b05ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-09-07T01:58:02.911645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_and_ingest_to_rocksdb(\n",
    "    ngram_size = 5,\n",
    "    repo_release_id = \"20200217\",\n",
    "    repo_corpus_id = \"eng\",\n",
    "    db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\",\n",
    "    file_range = (0, 19422),\n",
    "    random_seed = 42,\n",
    "    workers = 39,\n",
    "    use_threads = False,\n",
    "    ngram_type = \"tagged\",\n",
    "    overwrite = False,\n",
    "    write_batch_size = 100_000,\n",
    "    open_type = \"bulk_write\",\n",
    "    post_compact = False\n",
    ")"
   ],
   "id": "65902ca87dcac5b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mStart Time: 2025-09-06 21:58:02\u001B[0m\n",
      "\u001B[4m\n",
      "Download & Ingestion Configuration\u001B[0m\n",
      "Ngram repository:           https://storage.googleapis.com/books/ngrams/books/20200217/eng/eng-5-ngrams_exports.html\n",
      "RocksDB database path:      /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\n",
      "File index range:           0 to 19422 (count ~ 19423)\n",
      "Total files available:      19423\n",
      "Files to process:           9657\n",
      "First file URL:             http://storage.googleapis.com/books/ngrams/books/20200217/eng/5-16099-of-19423.gz\n",
      "Last file URL:              http://storage.googleapis.com/books/ngrams/books/20200217/eng/5-03676-of-19423.gz\n",
      "Ngram size:                 5\n",
      "Ngram filtering:            tagged\n",
      "Overwrite mode:             False\n",
      "Files to skip (processed):  9766\n",
      "Write batch size:           100,000\n",
      "Worker processes/threads:   39 (processes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:   4%|\u001B[34m▍         \u001B[0m| 411/9657 [10:44<2:19:25,  1.11files/s] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Count the Raw Records",
   "id": "8cc99b80b7c8791e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\"\n",
    "\n",
    "count = count_db_items(\n",
    "    db_path,\n",
    "    progress_interval=50_000_000\n",
    ")"
   ],
   "id": "e9f88488d885ad3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sample the Raw Records",
   "id": "fd8b7eb012f166a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\"\n",
    "\n",
    "sample = reservoir_sampling(\n",
    "    db_path,\n",
    "    sample_size=50_000,\n",
    "    key_type=\"byte\",\n",
    "    progress_interval=100_000_000,\n",
    "    return_keys=True,\n",
    ")"
   ],
   "id": "242948002c466776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the Sample to a Testing Database",
   "id": "4a6b8185f56a0a6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams_test.db\"\n",
    "\n",
    "save_sample_to_db(\n",
    "    sample,\n",
    "    db_path,\n",
    "    overwrite=True\n",
    ")"
   ],
   "id": "9382030a0b4c18db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/1grams_test.db\"\n",
    "\n",
    "valid = verify_sample_db(\n",
    "    db_path,\n",
    "    show_count=50,\n",
    "    decode_output=True,\n",
    "    unpack_ngram=True\n",
    ")"
   ],
   "id": "fac63a081f38ca6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process the Ngrams",
   "id": "7b87630cc83eaebb"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-09T04:33:12.725393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SRC = Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\").resolve()\n",
    "DST = SRC.parent / \"5grams_processed.db\"\n",
    "TMP = SRC.parent / \"sst_tmp\"\n",
    "VOC = Path(\"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/vocab.txt\")\n",
    "\n",
    "if DST.exists():\n",
    "    shutil.rmtree(DST)\n",
    "if TMP.exists():\n",
    "    shutil.rmtree(TMP)\n",
    "\n",
    "p_cfg = PipelineConfig(\n",
    "    src_db=SRC,\n",
    "    dst_db=DST,\n",
    "    tmp_dir=TMP,\n",
    "\n",
    "    # Parallelism\n",
    "    readers=8,         # pool size (processes)\n",
    "    outer_writers=4,   # shard writers\n",
    "    inner_lanes=32,    # per-writer in-RAM combiner lanes\n",
    "\n",
    "    # Progress\n",
    "    progress_every_s=10.0,\n",
    "\n",
    "    # Dynamic reader pool (small slices -> better balance)\n",
    "    reader_slice_factor=16,\n",
    "    reader_slices=0,\n",
    "\n",
    "    # Stage A (source)\n",
    "    source_read_profile=\"read\",\n",
    "\n",
    "    # Stage B (sharded writers)\n",
    "    writer_profile=\"bulk_write:packed24\",\n",
    "    writer_disable_wal=True,\n",
    "\n",
    "    # Stage C (ingest -> final DB)\n",
    "    ingest_read_profile=\"read:packed24\",\n",
    "    ingest_write_profile=\"bulk_write:packed24\",\n",
    "    ingest_batch_bytes=256 << 20,\n",
    "    ingest_batch_items=500_000,\n",
    "    ingest_disable_wal=True,\n",
    "    finalize_shards=True\n",
    ")\n",
    "\n",
    "f_cfg = FilterConfig(\n",
    "    opt_lower = True,\n",
    "    opt_alpha = False,\n",
    "    opt_shorts = False,\n",
    "    opt_stops = False,\n",
    "    opt_lemmas = False,\n",
    "    min_len = 0,\n",
    "    stop_set = None,\n",
    "    lemma_gen = None,\n",
    "    vocab_path=VOC\n",
    "#    stop_set=stopwords,\n",
    "#    lemma_gen=lemmatizer,\n",
    ")\n",
    "\n",
    "build_processed_db_sharded(p_cfg, f_cfg)"
   ],
   "id": "ddab7723316c43f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING N-GRAM FILTER PIPELINE\n",
      "\n",
      "Phase 1: Input DB → Filtered RocksDB Shards\n",
      "=========================================================================================\n",
      "R=readers done | S=recs scanned | W=recs written | K=recs kept | R=throughput | T=elapsed\n",
      "                              ( statistics are cumulative )                              \n",
      "=========================================================================================\n",
      "R=0/8 | S=0 | W=0 | K=0% | R=0/s | T=10.1s\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Try rerunning the processing pipeline: (1) lowercasing and vocab, (2) alpha, stops, shorts, (2) lemmas.",
   "id": "f388e701f91e2dc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fda3c5dd36243758"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist_w2v (Singularity)",
   "language": "python",
   "name": "hist_w2v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
